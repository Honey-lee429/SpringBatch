https://docs.spring.io/spring-batch/docs/5.0.6/reference/html/whatsnew.html

what‚Äôs new in spring batch 5.0
spring batch 5.0 has the following major themes:

JAVA 17 REQUIREMENT

@enablebatchprocessing NO LONGER REQUIRED
previously, @enablebatchprocessing could be used to enable spring boot‚Äôs auto-configuration of spring batch. it is no
longer required and should be removed from applications that want to use boot‚Äôs auto-configuration. a bean that is
annotated with @enablebatchprocessing or that extends batch‚Äôs defaultbatchconfiguration can now be defined to tell the
auto-configuration to back off, allowing the application to take complete control of how batch is configured.

https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0.0-M5-Release-Notes

TAMANHO CHUNCK
quanto maior o chunk
‚úî maior a velocidade de tempo de execu√ß√£o
‚úî maior o uso de mem√≥ria. Se utilizarmos maquinas na nuvem que possuem recursos limitados √© poss√≠vel que o processo pare
‚úî se der erro em um, todos os registros do chunk ter√£o roolback. Afeta a capacidade de reinicializa√ß√£o do job


MULTIPLE BATCH JOBS
Running multiple batch jobs is no longer supported.
If the auto-configuration detects a single job is, it will be executed on startup.
If multiple jobs are found in the context, a job name to execute on startup must be supplied by the user using the
spring.batch.job.name property.
We can continue supporting packaging multiple jobs in the application, but when that's the case we should require users
to identify via a property which one job they want to be launched. This will require us to deprecate
spring.batch.job.names and replace it with spring.batch.job.name (or spring.batch.job-name).


TRANSACTION MANAGER
for multiplos datasource

RESTART SPRING BATCH
O restart do Spring Batch permite reiniciar trabalhos em lote que falharam ou foram interrompidos. Isso √© poss√≠vel
atrav√©s do JobRepository e Persistent State. O Spring n√£o roda os chunks que comitaram novamente, roda a partir do chunk
que deu erro.

TRANSA√á√ïES DISTRIBU√çDAS <atomikos>
injetar a biblioteca do atomikos no pom
criar o XADataSource para garantir que todos os bancos de dados tenham atomicitade

VARIOS STEPS
anotar no job com @Qualifier para identificar o step
podemos encapsular varios steps que contenha a mesma logica de negocio com um processo chamado Flow
https://github.com/giuliana-bezerra/springbatch-flows/blob/main/src/main/java/br/com/giulianabezerra/sbflows/BatchConfig.java

üìå Por que usar CompositeItemWriter?
Em vez de misturar a l√≥gica de atualiza√ß√£o do banco e o envio de eventos Kafka em um √∫nico writer, podemos separ√°-los.

Benef√≠cios do CompositeItemWriter:
‚úÖ Separa responsabilidades: Um writer s√≥ atualiza o banco e outro s√≥ envia para o Kafka.
‚úÖ Facilita a manuten√ß√£o: Podemos modificar cada writer sem impactar o outro.
‚úÖ Reutiliza√ß√£o: Se precisar usar apenas um dos writers em outro batch, fica mais f√°cil.

‚úÖ Vantagens do CompositeItemWriter
‚úî Separa as responsabilidades (Single Responsibility Principle - SRP)
‚úî Facilita a manuten√ß√£o e testes individuais de cada writer
‚úî Garante que ambos os writers sejam executados para cada item processado
‚úî Tratamento de Erros mais Granular: Se uma opera√ß√£o falhar, voc√™ pode gerenciar a transa√ß√£o de forma mais controlada.
‚úî Reutiliza√ß√£o de C√≥digo: Facilita a reutiliza√ß√£o dos ItemWriters em outros jobs.

‚úÖ Desvantagens / Desafios do CompositeItemWriter
üî∏ N√£o h√° garantia de atomicidade: O primeiro writer pode executar, mas o segundo pode falhar (exemplo: banco atualizado, mas Kafka falha).
üî∏ Se um writer falhar, o rollback pode ser problem√°tico:

O JdbcBatchItemWriter executa um commit autom√°tico por padr√£o.
O Kafka n√£o tem rollback autom√°tico; se um evento falhar, ele pode ser perdido.
üî∏ Pode ser mais dif√≠cil controlar transa√ß√µes: Se o banco atualiza mas o Kafka falha, os dados

üõ†Ô∏è Como Resolver Esse Problema?
Se voc√™ deseja garantir que ambas as opera√ß√µes sejam executadas de forma consistente, algumas abordagens podem ajudar:
1Ô∏è‚É£ Spring Batch + Transaction Management
‚úÖ Quando usar?
Quando pequenas inconsist√™ncias s√£o aceit√°veis (exemplo: um evento pode ser perdido em caso de falha).
Quando quer manter a implementa√ß√£o simples e j√° usa transa√ß√µes no banco.
‚ùå Problema:
O Kafka n√£o faz parte da transa√ß√£o. Se a grava√ß√£o no banco for bem-sucedida, mas o Kafka falhar, n√£o h√° rollback autom√°tico.
üí° Recomendado quando o Kafka n√£o precisa ter garantia 100% de entrega.

2Ô∏è‚É£ Outbox Pattern + CDC (Change Data Capture)
‚úÖ Quando usar?
Se garantia forte de entrega √© essencial.
Se N√ÉO pode perder mensagens no Kafka de jeito nenhum.
Se j√° usa uma ferramenta de CDC (como Debezium ou Kafka Connect) no sistema.
üí° Melhor abordagem para garantir atomicidade entre banco de dados e Kafka.
üí° Usado em arquiteturas com alto volume de eventos e necessidade de confiabilidade.
‚ùå Problema:
Introduz mais complexidade no sistema. Precisa criar uma tabela
Precisa de um processo extra para monitorar a tabela outbox e enviar eventos.

3Ô∏è‚É£ Listener para Enviar Kafka Ap√≥s o Commit
‚úÖ Quando usar?
Se quiser garantir que Kafka s√≥ ser√° chamado depois que o banco foi atualizado.
Se precisa de mais controle sobre quando os eventos s√£o disparados.
Quando j√° usa um Spring Batch Listener para acompanhar a execu√ß√£o dos Steps.
‚ùå Problema:
N√£o resolve o problema de falhas no Kafka (se falhar depois do commit, o evento pode ser perdido).
üí° Boa op√ß√£o se a entrega no Kafka n√£o precisa ser garantida 100%, mas quer evitar chamar Kafka antes do commit do banco.

4Ô∏è‚É£ Usar um ItemWriter personalizado que realize as duas opera√ß√µes dentro de um √∫nico m√©todo
Se voc√™ quer garantir que ambas as opera√ß√µes sejam consistentes dentro de um √∫nico m√©todo (garantir que tanto a
atualiza√ß√£o do banco quanto o envio para o Kafka ocorram), a melhor abordagem √©:
‚úÖ Usar @Transactional para gerenciar a atualiza√ß√£o do banco e o envio para Kafka no mesmo m√©todo. O @Transactional
assegura que as duas opera√ß√µes sejam feitas na mesma transa√ß√£o.

No Spring, podemos usar Spring Transactions para garantir que o banco de dados e o Kafka fiquem sincronizados dentro
de um √∫nico m√©todo.
üìå O m√©todo write() do ItemWriter √© chamado dentro de uma transa√ß√£o √∫nica, porque:
‚úÖ O @Transactional no write() garante que o banco e o Kafka sejam processados juntos.
‚úÖ Se o banco falhar, nada ser√° enviado ao Kafka (rollback).
‚úÖ Se o Kafka falhar, o banco tamb√©m ser√° revertido automaticamente.

Isso faz com que as duas opera√ß√µes sejam sempre executadas juntas. Se alguma delas falhar, nenhuma das duas ser√° confirmada!

Ex.:
@Component
public class ExpirarOfertasWriter implements ItemWriter<Oferta> {

    private final OfertaRepository ofertaRepository;
    private final KafkaTemplate<String, OfertaEvento> kafkaTemplate;

    public ExpirarOfertasWriter(OfertaRepository ofertaRepository, KafkaTemplate<String, OfertaEvento> kafkaTemplate) {
        this.ofertaRepository = ofertaRepository;
        this.kafkaTemplate = kafkaTemplate;
    }

    @Override
    @Transactional // üöÄ Garante que o banco e Kafka sejam atualizados juntos!
    public void write(Chunk<? extends Oferta> chunk) throws Exception {
        List<Oferta> ofertas = chunk.getItems();

        // Atualiza o banco de dados
        for (Oferta oferta : ofertas) {
            oferta.setStatus("expirado");
            ofertaRepository.save(oferta);
        }

        // Publica os eventos no Kafka
        for (Oferta oferta : ofertas) {
            OfertaEvento evento = new OfertaEvento(oferta.getId(), oferta.getStatus());
            kafkaTemplate.send("tarifa-kafka", evento);
        }
    }
}

üî• Alternativa: Garantir Kafka Ap√≥s o Commit do Banco
Se voc√™ quiser que o Kafka s√≥ seja chamado ap√≥s o commit da transa√ß√£o, podemos modificar o c√≥digo para usar TransactionSynchronizationManager:
import org.springframework.transaction.support.TransactionSynchronization;
import org.springframework.transaction.support.TransactionSynchronizationManager;

@Override
@Transactional
public void write(Chunk<? extends Oferta> chunk) throws Exception {
    List<Oferta> ofertas = chunk.getItems();

    // Atualiza o banco de dados primeiro
    for (Oferta oferta : ofertas) {
        oferta.setStatus("expirado");
        ofertaRepository.save(oferta);
    }

    // Registra o envio ao Kafka AP√ìS o commit do banco
    TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() {
        @Override
        public void afterCommit() {
            for (Oferta oferta : ofertas) {
                OfertaEvento evento = new OfertaEvento(oferta.getId(), oferta.getStatus());
                kafkaTemplate.send("tarifa-kafka", evento);
            }
        }
    });
}







